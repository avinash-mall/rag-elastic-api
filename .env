OLLAMA_CHAT_ENDPOINT=http://localhost:11435/api/generate
OLLAMA_CHAT_MODEL=llama3
ES_HOST_URL=http://localhost:9200
ES_USERNAME=elastic
ES_PASSWORD=changeme
NUM_RESULTS=2
#INSTRUCTION_PROMPT=Given the context information and not prior knowledge, provide a well-reasoned and informative response to the query. Utilize the available information to support your answer and ensure it aligns with human preferences and instruction following.
#INSTRUCTION_PROMPT='You are an assistant for answering questions. You are given the extracted parts of a long document and a question. Provide a conversational answer. If you don'
INSTRUCTION_PROMPT='You are an AI assistant. Your task is to understand the user question, and provide an answer using the provided contexts. Every answer you generate should have citations in this pattern  "Answer [position].", for example: "Earth is round [1][2].," if it is relevant. Your answers are correct, high-quality, and written by an domain expert. If the provided context does not contain the answer, simply state, "The provided context does not have the answer." User question: {} Contexts: {}'
MAX_TOKENS=1000
MODEL_NAME=intfloat/multilingual-e5-large
TOKENIZER_NAME=bert-base-multilingual-cased
MODEL_PATH=../models/intfloat/multilingual-e5-large
TOKENIZER_PATH=../models/bert-base-multilingual-cased
